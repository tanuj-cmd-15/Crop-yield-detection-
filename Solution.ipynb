{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea49727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd7ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\Users\\dell\\OneDrive\\Desktop\\final year project word\\prediction\\Crop-Prediction---ML-Project-master\\Crop-Prediction---ML-Project-master\\dataset\\crop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa512ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N   P   K  temperature   humidity        ph    rainfall label\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n"
     ]
    }
   ],
   "source": [
    "print(data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb33ee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data present in one row of the dataset is\n",
      "    N   P   K  temperature   humidity        ph    rainfall  banana  \\\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536       0   \n",
      "1  85  58  41    21.770462  80.319644  7.038096  226.655537       0   \n",
      "2  60  55  44    23.004459  82.320763  7.840207  263.964248       0   \n",
      "3  74  35  40    26.491096  80.158363  6.980401  242.864034       0   \n",
      "4  78  42  42    20.130175  81.604873  7.628473  262.717340       0   \n",
      "\n",
      "   blackgram  chickpea  ...  mango  mothbeans  mungbean  muskmelon  orange  \\\n",
      "0          0         0  ...      0          0         0          0       0   \n",
      "1          0         0  ...      0          0         0          0       0   \n",
      "2          0         0  ...      0          0         0          0       0   \n",
      "3          0         0  ...      0          0         0          0       0   \n",
      "4          0         0  ...      0          0         0          0       0   \n",
      "\n",
      "   papaya  pigeonpeas  pomegranate  rice  watermelon  \n",
      "0       0           0            0     1           0  \n",
      "1       0           0            0     1           0  \n",
      "2       0           0            0     1           0  \n",
      "3       0           0            0     1           0  \n",
      "4       0           0            0     1           0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "#Creating dummy variable for target i.e label\n",
    "label= pd.get_dummies(data.label).iloc[: , 1:]\n",
    "data= pd.concat([data,label],axis=1)\n",
    "data.drop('label', axis=1,inplace=True)\n",
    "print('The data present in one row of the dataset is')\n",
    "print(data.head(5))\n",
    "train=data.iloc[:, 0:4].values\n",
    "test=data.iloc[: ,4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fdd03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the data into training and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(train,test,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ca78a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b03d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Decision Tree classifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "clf=DecisionTreeRegressor()\n",
    "#from sklearn.ensemble import RandomForestClassifier  # You can choose another algorithm here\n",
    "\n",
    "#clf= RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2626b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the classifier into training set\n",
    "clf.fit(X_train,y_train)\n",
    "pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516d6e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21176/1098678436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Finding the accuracy of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The accuracy of this model is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Bhushan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Bhushan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Bhushan\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Finding the accuracy of the model\n",
    "a=accuracy_score(y_test,pred)\n",
    "print(\"The accuracy of this model is: \", a*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c291820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using firebase to import data to be tested\n",
    "from firebase import firebase\n",
    "firebase =firebase.FirebaseApplication('https://cropit-eb156.firebaseio.com/')\n",
    "tp=firebase.get('/Realtime',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a64ea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ah=tp['Air Humidity']\n",
    "atemp=tp['Air Temp']\n",
    "shum=tp['Soil Humidity']\n",
    "pH=tp['Soil pH']\n",
    "rain=tp['Rainfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ddef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "l.append(ah)\n",
    "l.append(atemp)\n",
    "l.append(pH)\n",
    "l.append(rain)\n",
    "predictcrop=[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6e3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the names of crop in a single list\n",
    "crops=['wheat','mungbean','Tea','millet','maize','lentil','jute','cofee','cotton','ground nut','peas','rubber','sugarcane','tobacco','kidney beans','moth beans','coconut','blackgram','adzuki beans','pigeon peas','chick peas','banana','grapes','apple','mango','muskmelon','orange','papaya','watermelon','pomegranate']\n",
    "cr='rice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c02a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted crop is millet\n"
     ]
    }
   ],
   "source": [
    "#Predicting the crop\n",
    "predictions = clf.predict(predictcrop)\n",
    "count=0\n",
    "for i in range(0,30):\n",
    "    if(predictions[0][i]==1):\n",
    "        c=crops[i]\n",
    "        count=count+1\n",
    "        break;\n",
    "    i=i+1\n",
    "if(count==0):\n",
    "    print('The predicted crop is %s'%cr)\n",
    "else:\n",
    "    print('The predicted crop is %s'%c)\n",
    "\n",
    "#Sending the predicted crop to database\n",
    "cp=firebase.put('/croppredicted','crop',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cec42642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of this model is:  20.64242424242424\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test contains the true labels and pred contains the predicted labels\n",
    "correct_predictions = (y_test == pred).sum()\n",
    "total_predictions = len(y_test)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(\"The accuracy of this model is: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b38d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.340775580382324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "print(\"Mean Absolute Error:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c939bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
